{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70538337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.22.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (61.3.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (1.46.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mkrizek\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydicom pandas matplotlib numpy opencv-python tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d1e0bcd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BraTS21ID  MGMT_value\n",
       "0          0           1\n",
       "1          2           1\n",
       "2          3           0\n",
       "3          5           1\n",
       "4          6           1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydicom as dicom\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_dir = 'train/'\n",
    "patients = os.listdir(data_dir)\n",
    "labels_df = pd.read_csv('train_labels (1).csv')\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "412eb29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for patient in patients[:3]:\n",
    "    label = labels_df._get_value(int(patient),'MGMT_value')\n",
    "    path = data_dir + patient\n",
    "    slices = [dicom.read_file(path + '/' + s + '/' + c) for s in os.listdir(path)\n",
    "        for c in os.listdir(path+'/'+s)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "    print('(', i,')', len(slices), slices[0].pixel_array.shape)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00903ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea0b6a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "50\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "100\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "150\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "200\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "250\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "300\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "350\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "400\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "labeled\n",
      "read\n",
      "resized\n",
      "00586 this is unlabeled data\n",
      "00587 this is unlabeled data\n",
      "00588 this is unlabeled data\n",
      "00589 this is unlabeled data\n",
      "00590 this is unlabeled data\n",
      "00591 this is unlabeled data\n",
      "00593 this is unlabeled data\n",
      "00594 this is unlabeled data\n",
      "00596 this is unlabeled data\n",
      "00597 this is unlabeled data\n",
      "00598 this is unlabeled data\n",
      "00599 this is unlabeled data\n",
      "00601 this is unlabeled data\n",
      "00602 this is unlabeled data\n",
      "00604 this is unlabeled data\n",
      "00605 this is unlabeled data\n",
      "00606 this is unlabeled data\n",
      "00607 this is unlabeled data\n",
      "00608 this is unlabeled data\n",
      "00610 this is unlabeled data\n",
      "00611 this is unlabeled data\n",
      "00612 this is unlabeled data\n",
      "00613 this is unlabeled data\n",
      "00615 this is unlabeled data\n",
      "00616 this is unlabeled data\n",
      "00618 this is unlabeled data\n",
      "00619 this is unlabeled data\n",
      "00620 this is unlabeled data\n",
      "00621 this is unlabeled data\n",
      "00622 this is unlabeled data\n",
      "00623 this is unlabeled data\n",
      "00624 this is unlabeled data\n",
      "00625 this is unlabeled data\n",
      "00626 this is unlabeled data\n",
      "00628 this is unlabeled data\n",
      "00630 this is unlabeled data\n",
      "00631 this is unlabeled data\n",
      "00636 this is unlabeled data\n",
      "00638 this is unlabeled data\n",
      "00639 this is unlabeled data\n",
      "00640 this is unlabeled data\n",
      "00641 this is unlabeled data\n",
      "00642 this is unlabeled data\n",
      "00645 this is unlabeled data\n",
      "00646 this is unlabeled data\n",
      "00649 this is unlabeled data\n",
      "00650 this is unlabeled data\n",
      "450\n",
      "00651 this is unlabeled data\n",
      "00652 this is unlabeled data\n",
      "00654 this is unlabeled data\n",
      "00655 this is unlabeled data\n",
      "00656 this is unlabeled data\n",
      "00657 this is unlabeled data\n",
      "00658 this is unlabeled data\n",
      "00659 this is unlabeled data\n",
      "00661 this is unlabeled data\n",
      "00663 this is unlabeled data\n",
      "00667 this is unlabeled data\n",
      "00668 this is unlabeled data\n",
      "00674 this is unlabeled data\n",
      "00675 this is unlabeled data\n",
      "00676 this is unlabeled data\n",
      "00677 this is unlabeled data\n",
      "00679 this is unlabeled data\n",
      "00680 this is unlabeled data\n",
      "00682 this is unlabeled data\n",
      "00683 this is unlabeled data\n",
      "00684 this is unlabeled data\n",
      "00685 this is unlabeled data\n",
      "00686 this is unlabeled data\n",
      "00687 this is unlabeled data\n",
      "00688 this is unlabeled data\n",
      "00690 this is unlabeled data\n",
      "00691 this is unlabeled data\n",
      "00692 this is unlabeled data\n",
      "00693 this is unlabeled data\n",
      "00694 this is unlabeled data\n",
      "00697 this is unlabeled data\n",
      "00698 this is unlabeled data\n",
      "00703 this is unlabeled data\n",
      "00704 this is unlabeled data\n",
      "00705 this is unlabeled data\n",
      "00706 this is unlabeled data\n",
      "00707 this is unlabeled data\n",
      "00708 this is unlabeled data\n",
      "00709 this is unlabeled data\n",
      "00714 this is unlabeled data\n",
      "00715 this is unlabeled data\n",
      "00716 this is unlabeled data\n",
      "00718 this is unlabeled data\n",
      "00723 this is unlabeled data\n",
      "00724 this is unlabeled data\n",
      "00725 this is unlabeled data\n",
      "00727 this is unlabeled data\n",
      "00728 this is unlabeled data\n",
      "00729 this is unlabeled data\n",
      "00730 this is unlabeled data\n",
      "500\n",
      "00731 this is unlabeled data\n",
      "00732 this is unlabeled data\n",
      "00733 this is unlabeled data\n",
      "00734 this is unlabeled data\n",
      "00735 this is unlabeled data\n",
      "00736 this is unlabeled data\n",
      "00737 this is unlabeled data\n",
      "00739 this is unlabeled data\n",
      "00740 this is unlabeled data\n",
      "00742 this is unlabeled data\n",
      "00744 this is unlabeled data\n",
      "00746 this is unlabeled data\n",
      "00747 this is unlabeled data\n",
      "00750 this is unlabeled data\n",
      "00751 this is unlabeled data\n",
      "00753 this is unlabeled data\n",
      "00756 this is unlabeled data\n",
      "00757 this is unlabeled data\n",
      "00758 this is unlabeled data\n",
      "00759 this is unlabeled data\n",
      "00760 this is unlabeled data\n",
      "00764 this is unlabeled data\n",
      "00765 this is unlabeled data\n",
      "00767 this is unlabeled data\n",
      "00768 this is unlabeled data\n",
      "00772 this is unlabeled data\n",
      "00773 this is unlabeled data\n",
      "00774 this is unlabeled data\n",
      "00775 this is unlabeled data\n",
      "00777 this is unlabeled data\n",
      "00778 this is unlabeled data\n",
      "00780 this is unlabeled data\n",
      "00781 this is unlabeled data\n",
      "00782 this is unlabeled data\n",
      "00784 this is unlabeled data\n",
      "00787 this is unlabeled data\n",
      "00788 this is unlabeled data\n",
      "00789 this is unlabeled data\n",
      "00791 this is unlabeled data\n",
      "00792 this is unlabeled data\n",
      "00793 this is unlabeled data\n",
      "00794 this is unlabeled data\n",
      "00795 this is unlabeled data\n",
      "00796 this is unlabeled data\n",
      "00797 this is unlabeled data\n",
      "00799 this is unlabeled data\n",
      "00800 this is unlabeled data\n",
      "00801 this is unlabeled data\n",
      "00802 this is unlabeled data\n",
      "00803 this is unlabeled data\n",
      "550\n",
      "00804 this is unlabeled data\n",
      "00805 this is unlabeled data\n",
      "00806 this is unlabeled data\n",
      "00807 this is unlabeled data\n",
      "00808 this is unlabeled data\n",
      "00809 this is unlabeled data\n",
      "00810 this is unlabeled data\n",
      "00811 this is unlabeled data\n",
      "00814 this is unlabeled data\n",
      "00816 this is unlabeled data\n",
      "00818 this is unlabeled data\n",
      "00819 this is unlabeled data\n",
      "00820 this is unlabeled data\n",
      "00823 this is unlabeled data\n",
      "00824 this is unlabeled data\n",
      "00828 this is unlabeled data\n",
      "00830 this is unlabeled data\n",
      "00834 this is unlabeled data\n",
      "00836 this is unlabeled data\n",
      "00837 this is unlabeled data\n",
      "00838 this is unlabeled data\n",
      "00839 this is unlabeled data\n",
      "00840 this is unlabeled data\n",
      "00998 this is unlabeled data\n",
      "00999 this is unlabeled data\n",
      "01000 this is unlabeled data\n",
      "01001 this is unlabeled data\n",
      "01002 this is unlabeled data\n",
      "01003 this is unlabeled data\n",
      "01004 this is unlabeled data\n",
      "01005 this is unlabeled data\n",
      "01007 this is unlabeled data\n",
      "01008 this is unlabeled data\n",
      "01009 this is unlabeled data\n",
      "01010 this is unlabeled data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkrizek\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "IMG_PX_SIZE = 50\n",
    "HM_SLICES = 20\n",
    "\n",
    "def chunks (l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "    \n",
    "def mean(l):\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "\n",
    "def process_data(patient, labels_df, img_px_size=50, hm_slices=20, visualize=False):\n",
    "    # Reading in the labels into a dataframe\n",
    "    label = labels_df._get_value(int(patient), 'MGMT_value')\n",
    "\n",
    "    path = data_dir + patient\n",
    "    slices = [dicom.read_file(path + '/' + s + '/' + c) for s in os.listdir(path)\n",
    "        for c in os.listdir(path+'/'+s)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))    \n",
    "    \n",
    "    \n",
    "    new_slices = []\n",
    "    slices = [cv2.resize(np.array(each_slice.pixel_array), (IMG_PX_SIZE, IMG_PX_SIZE)) for each_slice in slices]    \n",
    "    \n",
    "    # Calculating the chunk size to produce HM_SLICES\n",
    "    chunk_size = math.ceil(len(slices)/HM_SLICES)\n",
    "    \n",
    "    # Iterating through the slices and creating chunks\n",
    "    for slice_chunk in chunks(slices, chunk_size):\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        new_slices.append(slice_chunk)\n",
    "    \n",
    "    while len(new_slices) < HM_SLICES:\n",
    "        new_slices.append(new_slices[-1])\n",
    "        \n",
    "    # Averaging the last slice (if it is larger than the expected # of slices) into the 2nd\n",
    "    # to last slice.\n",
    "    if len(new_slices) == HM_SLICES + 2:\n",
    "        new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1], new_slices[HM_SLICES]])))\n",
    "        del new_slices[HM_SLICES]\n",
    "        new_slices[HM_SLICES-1] = new_val\n",
    "        \n",
    "    # Averaging the last slice (if it is larger than the expected # of slices) into the 2nd\n",
    "    # to last slice.\n",
    "    if len(new_slices) == HM_SLICES + 2:\n",
    "        new_val = list(map(mean, zip(*[new_slices[HM_SLICES-1], new_slices[HM_SLICES]])))\n",
    "        del new_slices[HM_SLICES]\n",
    "        new_slices[HM_SLICES-1] = new_val\n",
    "        \n",
    "    # Allows for small subsections of the data to be graphed out.    \n",
    "    if visualize:\n",
    "        fig = plt.figure()\n",
    "        for num, each_slice in enumerate(slices[:12]):\n",
    "            y = fig.add_subplot(4,5,num+1)\n",
    "            y.imshow(each_slice)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    # Creating the one-hot array values for the dataset    \n",
    "    if label == 1: \n",
    "        label = np.array([0,1])\n",
    "            \n",
    "    elif label == 0: \n",
    "        label = np.array([1,0])\n",
    "        \n",
    "    return np.array(new_slices), label\n",
    "\n",
    "\n",
    "\n",
    "large_data = []\n",
    "\n",
    "for num, patient in enumerate(patients):\n",
    "    # Making sure that progress is being made.\n",
    "    if num%50==0:\n",
    "        print(num)\n",
    "        \n",
    "    try:\n",
    "        img_data,label = process_data(patient, labels_df, img_px_size=IMG_PX_SIZE, hm_slices=HM_SLICES)\n",
    "        large_data.append([img_data, label])\n",
    "    # When a lebel does not exist for a patient, print it out    \n",
    "    except KeyError as e:\n",
    "        print(patient, 'this is unlabeled data')\n",
    "        \n",
    "np.save('processedData-{}-{}-{}.npy'.format(IMG_PX_SIZE, IMG_PX_SIZE, HM_SLICES), large_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f026a72",
   "metadata": {},
   "source": [
    "\\\\MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c472621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        0       1\n",
      "count                                                 403     403\n",
      "unique                                                403     403\n",
      "top     [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  [0, 1]\n",
      "freq                                                    1       1\n",
      "Epoch 1 completed out of 15 loss: 36336592217.5 success rate: 1.0\n",
      "Epoch 2 completed out of 15 loss: 10997468427.5 success rate: 1.0\n",
      "Epoch 3 completed out of 15 loss: 5018430406.625 success rate: 1.0\n",
      "Epoch 4 completed out of 15 loss: 3194952203.5 success rate: 1.0\n",
      "Epoch 5 completed out of 15 loss: 1564048579.25 success rate: 1.0\n",
      "Epoch 6 completed out of 15 loss: 1356080546.5 success rate: 1.0\n",
      "Epoch 7 completed out of 15 loss: 584811778.375 success rate: 1.0\n",
      "Epoch 8 completed out of 15 loss: 583369417.75 success rate: 1.0\n",
      "Epoch 9 completed out of 15 loss: 880164901.0 success rate: 1.0\n",
      "Epoch 10 completed out of 15 loss: 377539498.5625 success rate: 1.0\n",
      "Epoch 11 completed out of 15 loss: 318299816.0 success rate: 1.0\n",
      "Epoch 12 completed out of 15 loss: 323834764.25 success rate: 1.0\n",
      "Epoch 13 completed out of 15 loss: 715453251.0625 success rate: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "IMG_PX_SIZE = 50\n",
    "HM_SLICES = 20\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "x = tf.compat.v1.placeholder('float')#, [NONE, 20, 50, 50])\n",
    "y = tf.compat.v1.placeholder('float')\n",
    "\n",
    "keep_rate = 0.8\n",
    "keep_prob = tf.compat.v1.placeholder(tf.float32)\n",
    "\n",
    "load_data = np.load('processedData-50-50-20.npy', allow_pickle=True)\n",
    "train_data = load_data[:-100]\n",
    "validation_data = load_data[-100:]\n",
    "\n",
    "def conv3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1,1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool3d(x):\n",
    "    #                        size of window         movement of window\n",
    "    return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "def convolutional_neural_network(x):\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([3,3,3,1,32])),\n",
    "               'W_conv2':tf.Variable(tf.random_normal([3,3,3,32,64])),\n",
    "               'W_fc':tf.Variable(tf.random_normal([54080,1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1024, num_classes]))}\n",
    "\n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "               'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "               'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "               'out':tf.Variable(tf.random_normal([num_classes]))}\n",
    "\n",
    "    x = tf.reshape(x, shape=[-1, IMG_PX_SIZE, IMG_PX_SIZE, HM_SLICES, 1])\n",
    "\n",
    "    conv1 = tf.nn.relu(conv3d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool3d(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool3d(conv2)\n",
    "\n",
    "    fc = tf.reshape(conv2,[-1, 54080])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n",
    "    fc = tf.nn.dropout(fc, keep_rate)\n",
    "\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "\n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    \n",
    "    \n",
    "    print(pd.DataFrame(load_data).describe())\n",
    "    prediction = convolutional_neural_network(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    hm_epochs = 15\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        success_total = 0\n",
    "        attempt_total = 0\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for data in train_data:\n",
    "                attempt_total += 1\n",
    "                try:\n",
    "                    X = data[0]\n",
    "                    Y = data[1]\n",
    "\n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
    "                    epoch_loss += c\n",
    "                    success_total += 1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "            print('Epoch', epoch+1, 'completed out of',hm_epochs,'loss:',epoch_loss, 'success rate:', success_total/attempt_total)\n",
    "\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y))\n",
    "            #print(correct)\n",
    "\n",
    "            accuracy = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct, 'float'))\n",
    "            #print(accuracy)\n",
    "            z = []\n",
    "            t = []\n",
    "            iterator = 0\n",
    "            total_accuracy = 0\n",
    "            for i in validation_data:\n",
    "                z.append(i[0])\n",
    "                t.append(i[1])\n",
    "                total_accuracy += accuracy.eval({x:i[0], y:i[1]})\n",
    "                iterator += 1\n",
    "\n",
    "\n",
    "            print('Accuracy:', total_accuracy/iterator)\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9024e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    307\n",
       "0    278\n",
       "Name: MGMT_value, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.MGMT_value.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7f3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
